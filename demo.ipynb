{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from config import Config\n",
    "from datagen import DataGenerator, _relative_points, _pad_img\n",
    "from model import SphinxModel\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化数据集和模型\n",
    "\n",
    "#### 注意修改以下值：\n",
    "1. CUDA_VISIBLE_DEVICES\n",
    "2. cfg.load\n",
    "3. generate_set的模式\n",
    "\n",
    "#### 关于初始化和硬件占用\n",
    "1. 如果需要从验证集换到测试集，模型不需要重新初始化。dataset必须重新初始化\n",
    "2. 模型初始化后，关闭该页面不会终止显存占用，再次打开页面也不需要重新初始化\n",
    "3. 如果要释放显存，需要在页面内restart kernel，或在jupyter首页shutdown该页面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "cfg.load = \"sphinx_14\"\n",
    "\n",
    "dataset = DataGenerator(cfg)\n",
    "dataset.generate_set(train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SphinxModel(cfg, dataset)\n",
    "model.generate_model(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Session'):\n",
    "    model.Session = tf.Session()\n",
    "    model._init_variable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在训练集和验证集上进行测试\n",
    "\n",
    "#### 每次只测试1张图片。修改i控制图片位置\n",
    "#### 修改dataset.{valid_set, train_set} 控制训练集或验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get image info\n",
    "name = dataset.valid_set[i]\n",
    "point = dataset.data_dict[name]['points']\n",
    "label = dataset.data_dict[name]['label']\n",
    "weight = np.asarray(dataset.data_dict[name]['weight'])\n",
    "\n",
    "# open image\n",
    "img = dataset.open_img(dataset.train_img_dir, name)\n",
    "orig_size = max(img.shape)\n",
    "\n",
    "# pad image and points\n",
    "new_p = _relative_points(point, img.shape)\n",
    "img = _pad_img(img)\n",
    "\n",
    "# visualize ground truth\n",
    "gt_hm_visual = dataset._generate_hm(orig_size, cfg.img_size, new_p, weight, keep_invisible=False)\n",
    "gt_hm_visual = np.sum(gt_hm_visual, 2) * 255\n",
    "gt_hm_visual = cv2.resize(gt_hm_visual, (orig_size, orig_size), interpolation=cv2.INTER_LINEAR)\n",
    "gt_hm_visual = np.expand_dims(gt_hm_visual, 2)\n",
    "gt_visual = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) + gt_hm_visual.astype(np.int32)\n",
    "pred_visual = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# resize image for inference\n",
    "img = cv2.resize(img, (cfg.img_size, cfg.img_size), interpolation=cv2.INTER_LINEAR)\n",
    "img = img.astype(np.float32) / 255\n",
    "images = np.expand_dims(img, 0)\n",
    "\n",
    "# get prediction\n",
    "pred = model.Session.run(model.output[2], feed_dict={model.img: images})\n",
    "pred = pred[0]\n",
    "\n",
    "# calculate predictions from heatmap\n",
    "pred_idxes = np.zeros((model.num_points, 2), dtype=np.float32)\n",
    "total_dist = 0.0\n",
    "for j in range(model.num_points):\n",
    "    if weight[j] == 1:\n",
    "        index = np.unravel_index(pred[:, :, j].argmax(), (model.img_size, model.img_size))\n",
    "        index = (index[1], index[0])\n",
    "        pred_idx = np.array(index) / model.img_size * orig_size\n",
    "        pred_idxes[j, :] = pred_idx\n",
    "        total_dist += np.linalg.norm(pred_idx - new_p[j])\n",
    "\n",
    "# visualize prediction\n",
    "pred_hm_visual = dataset._generate_hm(orig_size, cfg.img_size, pred_idxes, weight, keep_invisible=False)\n",
    "pred_hm_visual = np.sum(pred_hm_visual, 2) * 255\n",
    "pred_hm_visual = cv2.resize(pred_hm_visual, (orig_size, orig_size), interpolation=cv2.INTER_LINEAR)\n",
    "pred_hm_visual = np.expand_dims(pred_hm_visual, 2)\n",
    "pred_visual = pred_visual + pred_hm_visual.astype(np.int32)        \n",
    "  \n",
    "# calc normalized average error\n",
    "if label <= 2:\n",
    "    norm_idx1 = new_p[5]\n",
    "    norm_idx2 = new_p[6]\n",
    "else:\n",
    "    norm_idx1 = new_p[15]\n",
    "    norm_idx2 = new_p[16]\n",
    "\n",
    "norm_dist = np.linalg.norm(norm_idx2 - norm_idx1)\n",
    "error = total_dist / norm_dist / np.sum(np.count_nonzero(weight))\n",
    "\n",
    "# show results\n",
    "plt.imshow(gt_visual)\n",
    "plt.show()\n",
    "plt.imshow(pred_visual)\n",
    "plt.show()\n",
    "print(\"image error:\", error)\n",
    "        \n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在测试集上测试\n",
    "\n",
    "#### 重新初始化了dataset. 使用test_generator进行测试\n",
    "#### 每次测试一张图片，不能控制测试进度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "dataset.generate_set(train = False)\n",
    "test_gen = dataset.test_generator(cfg.img_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traversal the test set\n",
    "images, categories, offsets, names, sizes = next(test_gen)\n",
    "prediction = model.Session.run(model.output[2], feed_dict={model.img: images})\n",
    "hms = prediction\n",
    "\n",
    "# init\n",
    "pred_idxes = np.zeros((model.num_points, 2), dtype=np.float32)\n",
    "img = images[0]\n",
    "hm = hms[0]\n",
    "offset = offsets[0]\n",
    "category = categories[0]\n",
    "name = names[0]\n",
    "size = sizes[0]\n",
    "\n",
    "# predict\n",
    "write_line = [name, category]\n",
    "for j in range(model.num_points):\n",
    "    if ut.VALID_POSITION[category][j] is 1:\n",
    "        index = np.unravel_index(hm[:, :, j].argmax(), (model.img_size, model.img_size))\n",
    "        index = (index[1], index[0])\n",
    "        point = np.array(index) / model.img_size * size\n",
    "        pred_idxes[j] = point\n",
    "        point -= offset\n",
    "        write_line.append(str(int(round(point[0]))) + '_' + str(int(round(point[1]))) + '_1')\n",
    "    else:\n",
    "        write_line.append('-1_-1_-1')\n",
    "print(write_line)\n",
    "    \n",
    "# visualize prediction\n",
    "pred_hm_visual = np.zeros((size, size, 3))\n",
    "pred_hm = dataset._generate_hm(size, size, pred_idxes, ut.VALID_POSITION[category], keep_invisible=False)\n",
    "pred_hm = np.sum(pred_hm, 2) * 255\n",
    "pred_hm_visual[:, :, 1] = pred_hm\n",
    "pred_visual = cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), (size, size), interpolation=cv2.INTER_LINEAR)\n",
    "pred_visual = pred_visual + pred_hm_visual.astype(np.int32)\n",
    "# show results\n",
    "plt.imshow(pred_visual)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
