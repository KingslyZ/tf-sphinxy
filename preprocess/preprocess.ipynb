{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "#### 说明\n",
    "1. 本预处理脚本负责将数据集分成上身、下身两部分，并剔除缺失了归一化（Normalization）点的数据\n",
    "2. 本脚本不进行数据增补。数据增补在训练时在线完成，详见datagen.py\n",
    "3. 代码分为训练集和测试集两部分。每部分可以单独运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_list = ['neckline_left', 'neckline_right', 'center_front', 'shoulder_left', 'shoulder_right',\n",
    "                   'armpit_left', 'armpit_right', 'waistline_left', 'waistline_right', 'cuff_left_in',\n",
    "                   'cuff_left_out', 'cuff_right_in', 'cuff_right_out', 'top_hem_left', 'top_hem_right',\n",
    "                   'waistband_left', 'waistband_right', 'hemline_left', 'hemline_right', 'crotch',\n",
    "                   'bottom_left_in', 'bottom_left_out', 'bottom_right_in', 'bottom_right_out']\n",
    "\n",
    "categories = {\n",
    "    'all': {'blouse', 'dress', 'outwear', 'skirt', 'trousers'},\n",
    "    'top': {'blouse', 'dress', 'outwear'},\n",
    "    'bottom': {'skirt', 'trousers'}\n",
    "}\n",
    "\n",
    "weights = {\n",
    "    'blouse': np.array([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0]),\n",
    "    'dress': np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "        0, 0]),\n",
    "    'outwear': np.array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0]),\n",
    "    'skirt': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
    "        0, 0]),\n",
    "    'trousers': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
    "        1, 1])\n",
    "}\n",
    "\n",
    "valid_points = {\n",
    "    'all': np.ones(24, dtype=np.int32),\n",
    "    'top': np.logical_or(np.logical_or(weights['blouse'], weights['dress']),weights['outwear']),\n",
    "    'bottom': np.logical_or(weights['skirt'], weights['trousers'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集\n",
    "1. 遍历训练集数据，剔除并统计非法数据（缺失归一化点）\n",
    "2. 统计训练集关键点数量 \n",
    "3. 通过general_category选择上装(top)和下装(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_set(source, target, general_category = 'all'):\n",
    "    with open(source, newline='') as infile:\n",
    "        spamreader = csv.reader(infile)\n",
    "        with open(target, 'w', newline='') as outfile:\n",
    "            spamwriter = csv.writer(outfile, delimiter=' ')\n",
    "            \n",
    "            # keep track of some variables\n",
    "            head = True\n",
    "            image_count = {'blouse':[0, 0], 'dress':[0, 0], 'outwear':[0, 0], 'skirt':[0, 0], 'trousers':[0, 0]}\n",
    "            points_to_save = valid_points[general_category]\n",
    "            category_to_save = categories[general_category]\n",
    "            \n",
    "            # process every row\n",
    "            for row in spamreader:\n",
    "                # skip the header row\n",
    "                if head:\n",
    "                    head = False\n",
    "                    continue\n",
    "                    \n",
    "                bad_data = False\n",
    "                category = row[1]\n",
    "                \n",
    "                if category not in category_to_save:\n",
    "                    continue\n",
    "                \n",
    "                # parse data\n",
    "                this_row = [row[0].split('/')[-1], category]\n",
    "                for i in range(2, 26):\n",
    "                    if points_to_save[i-2] == False:\n",
    "                        continue\n",
    "                        \n",
    "                    x, y, v = row[i].split('_')\n",
    "\n",
    "                    # pick out data with invalid points\n",
    "                    if v == '1' and weights[category][i-2] == 0:\n",
    "                        bad_data = True\n",
    "                        break\n",
    "                    \n",
    "                    if v == '1':\n",
    "                        point_count[i-2] += 1\n",
    "\n",
    "                    this_row += [x, y, v]\n",
    "\n",
    "                # pick out data without valid normalization points\n",
    "                if category in categories['top']:\n",
    "                    if row[7].split('_')[2] == \"-1\" or row[8].split('_')[2] == \"-1\":\n",
    "                        bad_data = True\n",
    "                else:\n",
    "                    if row[17].split('_')[2] == \"-1\" or row[18].split('_')[2] == \"-1\":\n",
    "                        bad_data = True\n",
    "                        \n",
    "                if bad_data:\n",
    "                    image_count[category][1] += 1    \n",
    "                else:\n",
    "                    image_count[category][0] += 1\n",
    "                    spamwriter.writerow(this_row)\n",
    "                    \n",
    "            return image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_count = np.zeros(24)\n",
    "\n",
    "for general_category in ['top', 'bottom']:\n",
    "    print('dataset:', general_category)\n",
    "    image_count = generate_train_set(\"data/train/Annotations/train.csv\", \n",
    "                                     'data/train/dataset_%s.csv' % general_category, general_category)\n",
    "    print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for general_category in ['top', 'bottom']:\n",
    "    print(general_category)\n",
    "    for i in range(len(point_count)):\n",
    "        if valid_points[general_category][i]:\n",
    "            print(points_list[i], ':', point_count[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集\n",
    "1. 遍历并统计测试集数据 \n",
    "2. 通过general_category选择上装(top)和下装(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_set(source, target, general_category = 'all'):\n",
    "    with open(source, newline='') as infile:\n",
    "        spamreader = csv.reader(infile)\n",
    "        with open(target, 'w', newline='') as outfile:\n",
    "            spamwriter = csv.writer(outfile)\n",
    "            \n",
    "            category_to_save = categories[general_category]\n",
    "            \n",
    "            head = True\n",
    "            \n",
    "            # process every row\n",
    "            for row in spamreader:\n",
    "                if head:\n",
    "                    spamwriter.writerow(row)\n",
    "                    head = False\n",
    "                    continue\n",
    "                    \n",
    "                category = row[1]\n",
    "                \n",
    "                if category not in category_to_save:\n",
    "                    continue\n",
    "                    \n",
    "                num_test_set[general_category] += 1\n",
    "                    \n",
    "                spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_set = {'top': 0, 'bottom': 0}\n",
    "\n",
    "for general_category in ['top', 'bottom']:\n",
    "    generate_test_set(\"data/test_b/test.csv\", \n",
    "                      'data/test_b/test_%s.csv' % general_category, general_category)\n",
    "    \n",
    "print(num_test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
